# Embedded Analytics Engine with DuckDB

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![DuckDB](https://img.shields.io/badge/Database-DuckDB-orange?style=for-the-badge&logo=duckdb&logoColor=white)
![Pandas](https://img.shields.io/badge/DataFrames-Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

---

## ğŸ‡§ğŸ‡· Motor de Analytics Embarcado com DuckDB

Este repositÃ³rio explora e demonstra o uso do **DuckDB como um motor de analytics embarcado**, ideal para cenÃ¡rios onde a anÃ¡lise de dados precisa ser realizada diretamente na aplicaÃ§Ã£o, sem a necessidade de um servidor de banco de dados separado. O DuckDB Ã© um banco de dados OLAP (Online Analytical Processing) in-process, otimizado para consultas analÃ­ticas rÃ¡pidas em grandes volumes de dados, tornando-o perfeito para **aplicaÃ§Ãµes de desktop, notebooks Jupyter, ferramentas de BI leves e processamento de dados local**.

### ğŸ¯ Objetivo

O principal objetivo deste projeto Ã© **fornecer exemplos prÃ¡ticos, cÃ³digo funcional e documentaÃ§Ã£o detalhada** para desenvolvedores e cientistas de dados que desejam integrar capacidades analÃ­ticas de alta performance diretamente em suas aplicaÃ§Ãµes. SerÃ£o abordados desde a instalaÃ§Ã£o e configuraÃ§Ã£o bÃ¡sica atÃ© o uso avanÃ§ado de SQL para anÃ¡lise de dados, integraÃ§Ã£o com Python e otimizaÃ§Ã£o de performance, com foco em **ingestÃ£o de dados de mÃºltiplas fontes, consultas complexas e gerenciamento de metadados**.

### âœ¨ Destaques

- **IngestÃ£o de Dados Multifonte**: DemonstraÃ§Ã£o de como ingerir dados de diversas fontes, como arquivos CSV, JSON e Parquet, diretamente no DuckDB, facilitando a consolidaÃ§Ã£o e anÃ¡lise de dados heterogÃªneos.
- **Consultas AnalÃ­ticas AvanÃ§adas**: ImplementaÃ§Ã£o de exemplos de consultas SQL complexas, incluindo agregaÃ§Ãµes, joins, subconsultas e funÃ§Ãµes de janela, para extrair insights profundos dos dados.
- **Gerenciamento de Metadados e Esquemas**: Funcionalidades para inspecionar e gerenciar o esquema de tabelas, criar e manipular views, e otimizar o banco de dados, oferecendo controle granular sobre o ambiente analÃ­tico.
- **IntegraÃ§Ã£o com Pandas**: Exemplos de como o DuckDB se integra perfeitamente com o Pandas, permitindo a conversÃ£o eficiente de resultados de consultas para DataFrames e vice-versa, para anÃ¡lise e manipulaÃ§Ã£o de dados em Python.
- **Performance Otimizada**: DuckDB Ã© projetado para consultas analÃ­ticas rÃ¡pidas, aproveitando ao mÃ¡ximo os recursos locais da mÃ¡quina, ideal para processamento de dados local.
- **FÃ¡cil IntegraÃ§Ã£o**: Pode ser facilmente incorporado em aplicaÃ§Ãµes Python, Java, C++, R, entre outras, sem dependÃªncias de servidor.
- **CÃ³digo Profissional**: Exemplos de cÃ³digo bem estruturados, seguindo as melhores prÃ¡ticas da indÃºstria, com foco em modularidade, reusabilidade e manutenibilidade.
- **DocumentaÃ§Ã£o Completa**: Cada exemplo Ã© acompanhado de documentaÃ§Ã£o detalhada, diagramas explicativos e casos de uso prÃ¡ticos para facilitar a compreensÃ£o e a aplicaÃ§Ã£o.
- **Testes IncluÃ­dos**: MÃ³dulos de cÃ³digo validados atravÃ©s de testes unitÃ¡rios e de integraÃ§Ã£o, garantindo a robustez e a confiabilidade das soluÃ§Ãµes propostas.

### ğŸš€ BenefÃ­cios do DuckDB em AÃ§Ã£o

O DuckDB oferece uma sÃ©rie de vantagens que o tornam uma escolha excelente para analytics embarcado e processamento de dados local. Este projeto ilustra como esses benefÃ­cios sÃ£o explorados:

1.  **Performance In-Process:** A arquitetura in-process do DuckDB elimina a sobrecarga de comunicaÃ§Ã£o de rede, resultando em consultas analÃ­ticas extremamente rÃ¡pidas, especialmente visÃ­vel em operaÃ§Ãµes complexas e grandes volumes de dados.

2.  **SQL PadrÃ£o e ExtensÃ­vel:** Suporta SQL padrÃ£o ANSI, facilitando a migraÃ§Ã£o e a integraÃ§Ã£o. AlÃ©m disso, a capacidade de criar views e executar scripts SQL complexos demonstra sua flexibilidade para cenÃ¡rios analÃ­ticos avanÃ§ados.

3.  **Processamento Colunar Eficiente:** Utiliza um modelo de armazenamento e processamento colunar, otimizado para cargas de trabalho analÃ­ticas, o que acelera significativamente as consultas que agregam grandes volumes de dados, como demonstrado nas funÃ§Ãµes de agregaÃ§Ã£o e percentil.

4.  **Zero-Copy com Formatos de Arquivo:** A capacidade de ler diretamente de arquivos Parquet, CSV, JSON e outros formatos populares sem ingestÃ£o prÃ©via Ã© crucial para a eficiÃªncia, minimizando o uso de memÃ³ria e o tempo de processamento, e Ã© um destaque na funÃ§Ã£o `import_from_csv`.

5.  **Leve e Sem Servidor:** NÃ£o requer configuraÃ§Ã£o de servidor, tornando-o ideal para aplicaÃ§Ãµes embarcadas e desenvolvimento local, como visto na inicializaÃ§Ã£o simples da classe `DuckDBAnalytics`.

6.  **IntegraÃ§Ã£o Profunda com Python:** A API Python robusta e fÃ¡cil de usar se integra perfeitamente com bibliotecas como Pandas, permitindo fluxos de trabalho de anÃ¡lise de dados eficientes e a manipulaÃ§Ã£o de resultados como DataFrames.

---

## ğŸ‡¬ğŸ‡§ Embedded Analytics Engine with DuckDB

This repository explores and demonstrates the use of **DuckDB as an embedded analytics engine**, ideal for scenarios where data analysis needs to be performed directly within the application, without the need for a separate database server. DuckDB is an in-process OLAP (Online Analytical Processing) database, optimized for fast analytical queries on large volumes of data, making it perfect for **desktop applications, Jupyter notebooks, lightweight BI tools, and local data processing**.

### ğŸ¯ Objective

The main objective of this project is to **provide practical examples, functional code, and detailed documentation** for developers and data scientists who want to integrate high-performance analytical capabilities directly into their applications. It will cover everything from basic installation and configuration to advanced SQL usage for data analysis, Python integration, and performance optimization, with a focus on **multi-source data ingestion, complex queries, and metadata management**.

### âœ¨ Highlights

- **Multi-Source Data Ingestion**: Demonstration of how to ingest data from various sources, such as CSV, JSON, and Parquet files, directly into DuckDB, facilitating the consolidation and analysis of heterogeneous data.
- **Advanced Analytical Queries**: Implementation of examples of complex SQL queries, including aggregations, joins, subqueries, and window functions, to extract deep insights from data.
- **Metadata and Schema Management**: Functionalities to inspect and manage table schemas, create and manipulate views, and optimize the database, offering granular control over the analytical environment.
- **Pandas Integration**: Examples of how DuckDB seamlessly integrates with Pandas, allowing efficient conversion of query results to DataFrames and vice-versa, for data analysis and manipulation in Python.
- **Optimized Performance**: DuckDB is designed for fast analytical queries, making the most of local machine resources, ideal for local data processing.
- **Easy Integration**: Can be easily embedded into Python, Java, C++, R, and other applications, without server dependencies.
- **Professional Code**: Well-structured code examples, following industry best practices, with a focus on modularity, reusability, and maintainability.
- **Complete Documentation**: Each example is accompanied by detailed documentation, explanatory diagrams, and practical use cases to facilitate understanding and application.
- **Tests Included**: Code modules validated through unit and integration tests, ensuring the robustness and reliability of the proposed solutions.

### ğŸ“Š Visualization

![DuckDB Analytics Architecture](diagrams/duckdb_analytics_architecture.png)

*Diagrama ilustrativo da arquitetura do motor de analytics embarcado DuckDB, mostrando a integraÃ§Ã£o com diferentes fontes de dados e o fluxo de processamento.*


---

## ğŸ› ï¸ Tecnologias Utilizadas / Technologies Used

| Categoria         | Tecnologia      | DescriÃ§Ã£o                                                                 |
| :---------------- | :-------------- | :------------------------------------------------------------------------ |
| **Linguagem**     | Python 3.9+     | Linguagem principal para desenvolvimento da interface com DuckDB.         |
| **Banco de Dados**| DuckDB          | Motor de banco de dados OLAP embarcado de alta performance.               |
| **DataFrames**    | Pandas          | Biblioteca para manipulaÃ§Ã£o e anÃ¡lise de dados em Python.                 |
| **SerializaÃ§Ã£o**  | CSV, JSON, Parquet | Formatos de arquivo suportados para ingestÃ£o e exportaÃ§Ã£o de dados.       |
| **Parquet Support**| PyArrow        | Biblioteca para leitura/escrita de arquivos Parquet.                      |
| **Testes**        | pytest          | Framework de testes para Python com cobertura de cÃ³digo.                  |
| **GeraÃ§Ã£o de Dados** | Faker        | Biblioteca para geraÃ§Ã£o de dados sintÃ©ticos para testes.                  |

---

## ğŸ“ Repository Structure

```
duckdb-embedded-analytics-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ duckdb_analytics.py      # Main DuckDB analytics class
â”‚   â””â”€â”€ advanced_example.py      # Advanced usage examples with synthetic data
â”œâ”€â”€ data/
â”‚   â””â”€â”€ examples/                # Example data files (CSV, JSON, Parquet)
â”œâ”€â”€ docs/                        # Comprehensive documentation
â”‚   â”œâ”€â”€ getting_started.md       # Getting started guide
â”‚   â”œâ”€â”€ api_reference.md         # Complete API documentation
â”‚   â””â”€â”€ use_cases.md             # Real-world use cases and examples
â”œâ”€â”€ tests/                       # Unit and integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_duckdb_analytics.py # Unit tests
â”‚   â””â”€â”€ test_integration.py      # Integration tests
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ setup.py                 # Project setup script
â”‚   â”œâ”€â”€ generate_data.py         # Sample data generator
â”‚   â””â”€â”€ run_tests.py             # Test runner with coverage
â”œâ”€â”€ diagrams/                    # Architecture diagrams
â”œâ”€â”€ images/                      # Images and screenshots
â”œâ”€â”€ .gitignore                   # Git ignore configuration
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ CONTRIBUTING.md              # Contribution guidelines
â”œâ”€â”€ CODE_OF_CONDUCT.md           # Code of conduct
â””â”€â”€ README.md                    # This file
```

---

## ğŸš€ Getting Started

Para comeÃ§ar, clone o repositÃ³rio e explore os diretÃ³rios `src/` e `docs/` para exemplos detalhados e instruÃ§Ãµes de uso. Certifique-se de ter as dependÃªncias necessÃ¡rias instaladas.

### PrÃ©-requisitos

- Python 3.9+
- `pip` (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

```bash
git clone https://github.com/galafis/duckdb-embedded-analytics-engine.git
cd duckdb-embedded-analytics-engine

# Instalar dependÃªncias Python
pip install -r requirements.txt

# Executar script de setup (opcional)
python scripts/setup.py
```

### Executar Testes

```bash
# Executar todos os testes
pytest tests/ -v

# Executar testes com cobertura
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# Ver relatÃ³rio de cobertura HTML
open htmlcov/index.html  # macOS/Linux
# ou
start htmlcov/index.html  # Windows
```

### Exemplo de Uso AvanÃ§ado (Python)

O exemplo abaixo demonstra a inicializaÃ§Ã£o da classe `DuckDBAnalytics`, a conexÃ£o com um banco de dados DuckDB, a ingestÃ£o de dados de diferentes fontes, a execuÃ§Ã£o de consultas analÃ­ticas complexas, o gerenciamento de views e a exportaÃ§Ã£o de resultados. Este cÃ³digo ilustra a flexibilidade e o poder do DuckDB como um motor de analytics embarcado.

```python
from src.duckdb_analytics import DuckDBAnalytics
import os
import pandas as pd
import json

if __name__ == "__main__":
    print("=" * 60)
    print("DuckDB Embedded Analytics Engine - Example")
    print("=" * 60)

    db_path = "my_analytics.duckdb"
    # Limpar o banco de dados anterior se existir
    if os.path.exists(db_path):
        os.remove(db_path)

    analytics = DuckDBAnalytics(db_path)
    analytics.connect()

    # --- 1. Criar e Ingerir Dados de Exemplo ---
    print("\n--- 1. Criando e Ingerindo Dados de Exemplo ---")
    # Criar tabela de vendas diretamente
    analytics.execute_query("""
        CREATE TABLE sales (
            id INTEGER,
            product VARCHAR,
            amount DOUBLE,
            sale_date DATE,
            region VARCHAR
        )
    """)
    analytics.execute_query("""
        INSERT INTO sales VALUES 
        (1, 'Laptop', 1200.00, '2025-01-01', 'North'), 
        (2, 'Mouse', 25.00, '2025-01-02', 'South'), 
        (3, 'Keyboard', 75.00, '2025-01-03', 'East'), 
        (4, 'Laptop', 1500.00, '2025-01-04', 'North'),
        (5, 'Monitor', 300.00, '2025-01-05', 'West'),
        (6, 'Mouse', 30.00, '2025-01-05', 'North')
    """)
    print("  Tabela 'sales' criada e populada.")

    # Ingerir dados de um CSV (simulado)
    csv_data = "id,customer_name,age,city\n101,Alice,30,New York\n102,Bob,24,Los Angeles"
    with open("data/customers.csv", "w") as f:
        f.write(csv_data)
    analytics.import_from_csv("data/customers.csv", "customers_from_csv")
    print("  Dados de 'customers.csv' ingeridos na tabela 'customers_from_csv'.")

    # Ingerir dados de um JSON (simulado)
    json_data = [
        {"order_id": 1001, "customer_id": 101, "total": 150.00, "order_date": "2025-01-01"},
        {"order_id": 1002, "customer_id": 102, "total": 200.50, "order_date": "2025-01-02"}
    ]
    with open("data/orders.json", "w") as f:
        json.dump(json_data, f)
    analytics.execute_query("CREATE TABLE orders AS SELECT * FROM read_json_auto('data/orders.json');")
    print("  Dados de 'orders.json' ingeridos na tabela 'orders'.")

    # --- 2. Consultas AnalÃ­ticas AvanÃ§adas ---
    print("\n--- 2. Consultas AnalÃ­ticas AvanÃ§adas ---")
    print("\nTop 3 Produtos por Receita e MÃ©dia de Vendas por RegiÃ£o:")
    result_df = analytics.fetch_data("""
        WITH ProductRevenue AS (
            SELECT 
                product,
                SUM(amount) as total_revenue
            FROM sales
            GROUP BY product
        ),
        RegionalSales AS (
            SELECT
                region,
                product,
                AVG(amount) as avg_regional_sale
            FROM sales
            GROUP BY region, product
        )
        SELECT 
            pr.product,
            pr.total_revenue,
            rs.region,
            rs.avg_regional_sale
        FROM ProductRevenue pr
        JOIN RegionalSales rs ON pr.product = rs.product
        ORDER BY pr.total_revenue DESC, rs.region
        LIMIT 5
    """)
    print(result_df)

    print("\nClientes com mais de uma compra (usando JOIN com orders):")
    customers_with_multiple_orders = analytics.fetch_data("""
        SELECT
            c.customer_name,
            COUNT(o.order_id) as total_orders
        FROM customers_from_csv c
        JOIN orders o ON c.id = o.customer_id
        GROUP BY c.customer_name
        HAVING COUNT(o.order_id) > 1
    """)
    print(customers_with_multiple_orders)

    # --- 3. Gerenciamento de Metadados e Esquemas ---
    print("\n--- 3. Gerenciamento de Metadados e Esquemas ---")
    # Criar e usar uma view
    analytics.create_view("sales_summary_view", "SELECT product, SUM(amount) as total_revenue FROM sales GROUP BY product")
    print("\nDados da View 'sales_summary_view':")
    print(analytics.fetch_data("SELECT * FROM sales_summary_view"))

    # Obter esquema da tabela
    print("\nEsquema da tabela 'sales':")
    print(analytics.get_table_schema("sales"))

    # --- 4. Exportar Dados ---
    print("\n--- 4. Exportando Dados ---")
    output_csv_path = "data/sales_output.csv"
    analytics.export_to_csv("SELECT * FROM sales WHERE region = 'North'", output_csv_path)
    if os.path.exists(output_csv_path):
        print(f"  Dados da regiÃ£o 'North' exportados para '{output_csv_path}'. ConteÃºdo:\n")
        with open(output_csv_path, "r") as f:
            print(f.read())
        os.remove(output_csv_path)

    # --- 5. Otimizar Banco de Dados ---
    print("\n--- 5. Otimizando Banco de Dados ---")
    analytics.vacuum_database()
    print("  Banco de dados otimizado (VACUUM executado).")

    analytics.disconnect()

    # Limpar arquivos gerados
    if os.path.exists(db_path):
        os.remove(db_path)
    if os.path.exists("data/customers.csv"):
        os.remove("data/customers.csv")
    if os.path.exists("data/orders.json"):
        os.remove("data/orders.json")

    print("\n==================================================")
    print("DemonstraÃ§Ã£o ConcluÃ­da.")
    print("==================================================")
```

---

## ğŸ“š DocumentaÃ§Ã£o

Para documentaÃ§Ã£o completa, consulte:

- **[Getting Started Guide](docs/getting_started.md)** - Guia de inÃ­cio rÃ¡pido com exemplos bÃ¡sicos
- **[API Reference](docs/api_reference.md)** - DocumentaÃ§Ã£o completa da API
- **[Use Cases](docs/use_cases.md)** - Casos de uso do mundo real com implementaÃ§Ãµes completas

## ğŸ§ª Testes e Cobertura

O projeto possui cobertura de testes abrangente:

- 15 testes unitÃ¡rios e de integraÃ§Ã£o
- Cobertura do mÃ³dulo principal (~62%)
- Testes compatÃ­veis com Python 3.9+

### Executar Testes Localmente

```bash
# Testes bÃ¡sicos
pytest tests/ -v

# Com cobertura detalhada
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# Teste especÃ­fico
pytest tests/test_duckdb_analytics.py::TestDuckDBAnalytics::test_ingest_csv -v
```

## ğŸ¯ Casos de Uso

### Business Intelligence
Crie dashboards de BI leves sem necessidade de servidor de banco de dados.

### Data Science
Integre anÃ¡lises SQL diretamente em notebooks Jupyter.

### ETL Pipelines
Processe e transforme dados localmente antes de enviar para o data warehouse.

### IoT Analytics
Analise dados de sensores localmente antes de enviar para a nuvem.

### Mobile Apps
AnÃ¡lises offline embarcadas em aplicativos mÃ³veis.

Veja [Use Cases](docs/use_cases.md) para implementaÃ§Ãµes completas.

## ğŸš€ Funcionalidades Principais

### âœ¨ IngestÃ£o Multi-Formato
- CSV, JSON e Parquet
- ImportaÃ§Ã£o direta sem conversÃµes
- Suporte a grandes volumes de dados

### ğŸ“Š Consultas SQL AvanÃ§adas
- SQL ANSI completo
- Window functions
- CTEs (Common Table Expressions)
- Joins complexos

### ğŸ”„ IntegraÃ§Ã£o Pandas
- ConversÃ£o bidirecional DataFrame â†” DuckDB
- Zero-copy quando possÃ­vel
- Performance otimizada

### ğŸ’¾ Gerenciamento de Metadados
- Rastreamento de esquemas
- HistÃ³rico de criaÃ§Ã£o
- InformaÃ§Ãµes de fonte de dados

### ğŸ› ï¸ UtilitÃ¡rios
- CriaÃ§Ã£o de views
- ExportaÃ§Ã£o para CSV
- ExecuÃ§Ã£o de scripts SQL
- OtimizaÃ§Ã£o de banco de dados

## ğŸ”§ Scripts UtilitÃ¡rios

O projeto inclui scripts Ãºteis no diretÃ³rio `scripts/`:

- **setup.py** - Configura o ambiente e verifica dependÃªncias
- **generate_data.py** - Gera dados sintÃ©ticos para testes
- **run_tests.py** - Executa testes com relatÃ³rio de cobertura

```bash
# Setup inicial
python scripts/setup.py

# Gerar dados de exemplo
python scripts/generate_data.py

# Executar testes completos
python scripts/run_tests.py
```

## ğŸ“Š Performance

DuckDB was designed from the ground up for analytical workloads:

- **Vectorized execution** for efficient batch processing
- **Columnar storage** well-suited for aggregation queries
- **In-process** â€” no network overhead

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! ğŸ‰

1. Leia o [Guia de ContribuiÃ§Ã£o](CONTRIBUTING.md)
2. Leia o [CÃ³digo de Conduta](CODE_OF_CONDUCT.md)
3. Fork o projeto
4. Crie sua feature branch (`git checkout -b feature/AmazingFeature`)
5. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
6. Push para a branch (`git push origin feature/AmazingFeature`)
7. Abra um Pull Request

## ğŸ› Reportar Bugs

Encontrou um bug? Por favor, abra uma [issue](https://github.com/galafis/duckdb-embedded-analytics-engine/issues) com:

- DescriÃ§Ã£o clara do problema
- Passos para reproduzir
- Comportamento esperado vs observado
- VersÃ£o do Python e sistema operacional

## ğŸ’¡ SugestÃµes

Tem uma ideia para melhorar o projeto? AdorarÃ­amos ouvir!

Abra uma [issue](https://github.com/galafis/duckdb-embedded-analytics-engine/issues) com a tag `enhancement`.

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸŒŸ Agradecimentos

- [DuckDB](https://duckdb.org/) - Pelo excelente banco de dados OLAP embarcado
- [Pandas](https://pandas.pydata.org/) - Pela biblioteca de manipulaÃ§Ã£o de dados
- [PyArrow](https://arrow.apache.org/docs/python/) - Pelo suporte a Parquet
- Todos os contribuidores que ajudaram a melhorar este projeto

## ğŸ“§ Contato

**Autor:** Gabriel Demetrios Lafis  
**Ano:** 2025  
**GitHub:** [@galafis](https://github.com/galafis)

## ğŸ”— Links Ãšteis

- [DuckDB Documentation](https://duckdb.org/docs/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Python Testing with pytest](https://docs.pytest.org/)

---

[â¬† Voltar ao topo](#embedded-analytics-engine-with-duckdb)